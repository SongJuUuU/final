# final

## 1. 문제 정의
- 야구는 시대가 지날수록 훈련법, 기술 그리고 역사에 의해 발전되어 왔음.
- 하지만 가끔은 이러한 사실을 망각하고, 현대 선수들이 과거 선수들보다 뛰어나다는 편협한 사고를 하게 됨.
- 이에 따라 '오타니가 1910년도에 태어났으면, 베이브 루스보다 위대한 선수였을 것이다'와 같은 주장이 제기됨.
- 이러한 주장의 타당성을 측정하기 위해 옛날 기록을 바탕으로 고대의 위대한 선수 측정기를 개발.
- 과거 선수들의 기록과 수상 데이터를 훈련 데이터로 사용.

---

## 2. 프로젝트 목표 및 성공 기준
### 주요 목표
- 과거 선수들의 위대함을 정량적으로 평가할 수 있는 모델 개발.
- 하이퍼파라미터 자동 최적화를 통한 최적의 모델 구성 도출.

### 세부 목표
#### 모델 성능
- **검증 손실(Validation Loss)**: < 0.3  
- **검증 정확도(Accuracy)**: > 0.9  

#### 학습 효율성
- **조기 종료 기준 도달 시간**: < 100 에포크  
- **GPU 메모리 사용량**: < 4GB  

#### 하이퍼파라미터 최적화
- **최소 시도 횟수**: 50회  
- **최적 파라미터 조합 도출**

---

## 3. 데이터 수집 및 처리
- **MLB 타격 기록**: 1871년부터의 데이터 전처리.
- **MVP 수상 데이터**와 결합.
- **결측치 및 이상치 처리** 수행.

---

## 4. 기술 개요
### 다층 퍼셉트론 (Multi-Layer Perceptron, MLP)
- **활성화 함수**:  
  - 은닉층: ReLU (Rectified Linear Unit)  
  - 출력층: Sigmoid  
- **손실 함수**: Binary Cross Entropy Loss  
- **옵티마이저**: Adam (learning rate = 0.001)

---

## 5. 과적합 방지를 위한 조절
- **Early Stopping**
- **L1/L2 정규화**
- **K-fold 교차 검증**
- **배치 정규화(Batch Normalization)** 추가

---

## 6. 조절한 하이퍼파라미터
### 1) 아키텍처 구조 실험
- **기본 모델**: 3층 신경망 (입력층 → 64 → 32 → 출력층)  
- **깊은 모델**: 5층 신경망 (입력층 → 128 → 64 → 32 → 16 → 출력층)  
- **넓은 모델**: 더 많은 뉴런을 가진 모델 (입력층 → 256 → 128 → 출력층)  

### 2) 하이퍼파라미터 실험
- **학습률 (Learning Rate)**: 0.1, 0.01, 0.001, 0.0001  
- **배치 크기 (Batch Size)**: 16, 32, 64, 128  
- **에포크 수 (Epochs)**: 50, 100, 200  
- **드롭아웃 비율**: 0.1, 0.3, 0.5  
- **은닉층 크기**: (64, 32), (128, 64), (256, 128)  

### 3) 최적화 기법
- **옵티마이저**: Adam, SGD(모멘텀 적용), RMSprop  
- **학습률 스케줄링**: ReduceLROnPlateau  
- **정규화**: Dropout, Batch Normalization, L1/L2 정규화  

---

## 7. 결과
### 모델 성능
- **검증 손실 (Validation Loss)**: 평균 0.2578 (training loss와의 차이: 0.04233, 과적합 크지 않음)  
- **검증 정확도 (Accuracy)**: 평균 0.9105  

### 학습 효율성
- **조기 종료 기준 도달 시간**: < 100 에포크  
- **GPU 메모리 사용량**: < 4GB  

### 하이퍼파라미터 최적화
- **최소 50회 시도**: 성공  
- **최적 파라미터 조합 도출**:
  1. **아키텍처**: 3층 신경망  
  2. **학습률**: 0.001  
  3. **배치 크기**: 32  

---

## 9. 시각화
- **Repository 내 PNG 파일로 저장**
